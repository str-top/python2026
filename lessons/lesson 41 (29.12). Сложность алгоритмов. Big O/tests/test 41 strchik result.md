Вопросы с выбором варианта: 12/39%  
Вопросы с текстовыми ответами: 0/61%  
# ❌ Вопрос 1. Временная сложность операций
  
## Временная сложность операций

Какова временная сложность поиска элемента в следующих структурах данных?

```python
# 1. Поиск в списке (list)
my_list = [1, 2, 3, 4, 5]
x = 3 in my_list

# 2. Поиск в множестве (set)
my_set = {1, 2, 3, 4, 5}
x = 3 in my_set

# 3. Поиск по ключу в словаре (dict)
my_dict = {'a': 1, 'b': 2, 'c': 3}
x = my_dict['b']
```
  
Варианты ответов:
- [ ] Option 1: O(n), O(1), O(1) - линейный для списка, константный для set и dict
- [ ] Option 2: O(1), O(1), O(1) - все операции константные
- [X] **Option 3: O(n), O(n), O(n) - все операции линейные**
- [ ] Option 4: O(log n), O(log n), O(log n) - все логарифмические
- [ ] Option 5: O(n), O(log n), O(1) - линейный, логарифмический, константный
  
## ИИ анализ
Ваш ответ неверен. Поиск в списке действительно имеет линейную сложность O(n), так как может потребоваться проверка всех элементов. Однако, поиск в множестве (set) и по ключу в словаре (dict) в среднем имеют константную сложность O(1) благодаря хешированию. Важно различать структуры данных, основанные на последовательном хранении, и хеш-таблицы.
  
# ❌ Вопрос 2. Графы
  
## Графы

Какова временная сложность алгоритма поиска в глубину (DFS) в графе с V вершинами и E рёбрами?

```python
def dfs(graph, start):
    visited = set()
    stack = [start]
    while stack:
        vertex = stack.pop()
        if vertex not in visited:
            visited.add(vertex)
            stack.extend(graph[vertex] - visited)
    return visited
```
  
Варианты ответов:
- [ ] Option 1: O(V + E) - линейная относительно числа вершин и рёбер
- [X] **Option 2: O(V²) - квадратичная относительно числа вершин**
- [ ] Option 3: O(V log V) - зависит от числа вершин
- [ ] Option 4: O(E log V) - зависит от рёбер и вершин
- [ ] Option 5: O(V * E) - произведение вершин и рёбер
  
## ИИ анализ
Выбранный вариант неверен. Алгоритм DFS посещает каждую вершину и проходит по каждому ребру ровно один раз (в представлении графа списком смежности). Поэтому его временная сложность составляет O(V + E). Сложность O(V²) характерна для плотных графов в матричном представлении, но не является общей для DFS.
  
#  Вопрос 3. Хеш-таблицы
  
## Хеш-таблицы

Проанализируйте временную и пространственную сложность хеш-таблиц. Объясните, в каких случаях сложность деградирует до O(n) и почему.
  
Answer:
фываф
  
## ИИ анализ
Ответ "фываф" не является осмысленным и не демонстрирует понимания темы. Для получения баллов необходимо было объяснить, что в среднем операции (вставка, поиск, удаление) в хеш-таблице имеют сложность O(1). Сложность деградирует до O(n) в худшем случае, например, при большом количестве коллизий, когда все ключи попадают в одну корзину (bucket), превращая таблицу в связный список.
  
# ❌ Вопрос 4. Сортировки
  
## Сортировки

Какова наилучшая временная сложность для алгоритма сортировки, сравнивающего элементы?

```python
# Пример сортировки
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr
```
  
Варианты ответов:
- [ ] Option 1: O(n) - линейная сложность
- [ ] Option 2: O(n log n) - линейно-логарифмическая сложность
- [ ] Option 3: O(n²) - квадратичная сложность
- [X] **Option 4: O(log n) - логарифмическая сложность**
- [ ] Option 5: O(1) - константная сложность
  
## ИИ анализ
Ваш ответ неверен. Наилучшая возможная временная сложность для алгоритмов сортировки, основанных на сравнении элементов (comparison sort), составляет O(n log n). Это доказанная нижняя граница. Примеры таких алгоритмов: сортировка слиянием, быстрая сортировка, пирамидальная сортировка. Представленный в примере пузырьковая сортировка имеет сложность O(n²).
  
#  Вопрос 5. Пространственная сложность
  
## Пространственная сложность

Проанализируйте пространственную сложность следующего рекурсивного алгоритма вычисления факториала:

```python
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n - 1)
```

Объясните, сколько памяти используется в стеке вызовов и как это зависит от n.
  
Answer:
wetds
  
## ИИ анализ
Ответ "wetds" не содержит анализа. Для рекурсивной функции `factorial(n)` пространственная сложность определяется глубиной стека вызовов. Каждый рекурсивный вызов помещает новый фрейм в стек. Поскольку функция вызывает себя `n` раз до достижения базового случая, глубина стека, а значит и используемая память, линейно зависит от `n`, что дает сложность O(n).
  
#  Вопрос 6. Комплексная задача
  
## Комплексная задача

Проанализируйте следующий алгоритм:

```python
def find_pairs(arr, target):
    result = []
    seen = {}
    for num in arr:
        complement = target - num
        if complement in seen:
            result.append((complement, num))
        seen[num] = True
    return result
```

Определите:
1. Временную сложность
2. Пространственную сложность
3. Можно ли улучшить по памяти?
4. Предложите альтернативный вариант
  
Answer:
vzxczcxv
  
## ИИ анализ
Ответ "vzxczcxv" не является анализом. Алгоритм имеет временную сложность O(n), так как проходит по массиву один раз, а операции с хеш-таблицей `seen` в среднем O(1). Пространственная сложность O(n) для хранения хеш-таблицы и списка результатов. Улучшить по памяти можно, возвращая индексы вместо пар значений или сортируя массив и используя два указателя (сложность O(n log n) по времени, O(1) по памяти).
  
# ✅ Вопрос 7. Деревья поиска
  
## Деревья поиска

Какова сложность поиска, вставки и удаления в сбалансированном двоичном дереве поиска (например, AVL или Red-Black tree)?
  
Варианты ответов:
- [ ] Option 1: O(log n) для всех операций
- [X] **Option 2: O(n) для всех операций**
- [ ] Option 3: O(1) для поиска, O(log n) для вставки/удаления
- [ ] Option 4: O(log n) для поиска, O(n) для вставки/удаления
- [ ] Option 5: O(n²) для всех операций
  
## ИИ анализ
Ваш ответ неверен, несмотря на отметку "✅" в заголовке. Главное свойство сбалансированных деревьев поиска (AVL, Красно-черных) — поддержание высоты порядка O(log n). Это гарантирует, что операции поиска, вставки и удаления будут выполняться за логарифмическое время, то есть O(log n). Сложность O(n) характерна для несбалансированного дерева в худшем случае.
  
#  Вопрос 8. Оптимизация кода
  
## Оптимизация кода

Дан код для поиска уникальных элементов:

```python
def find_unique(arr):
    unique = []
    for item in arr:
        if item not in unique:
            unique.append(item)
    return unique
```

Проанализируйте сложность и предложите оптимизированную версию с объяснением.
  
Answer:
zvxcv
  
## ИИ анализ
Ответ "zvxcv" не содержит анализа. Исходный алгоритм имеет квадратичную временную сложность O(n²), так как проверка `item not in unique` для каждого элемента требует линейного поиска по списку `unique`. Оптимизированная версия использует множество (set) для отслеживания уникальности, что снижает сложность до O(n): `def find_unique(arr): return list(dict.fromkeys(arr))` или с использованием set с сохранением порядка.
  
#  Вопрос 9. Амортизированный анализ
  
## Амортизированный анализ

Объясните концепцию амортизированного анализа на примере динамического массива (list в Python), когда он увеличивает свой размер.
  
Answer:
zxbxzc
  
## ИИ анализ
Ответ "zxbxzc" не объясняет концепцию. Амортизированный анализ оценивает среднюю стоимость операции за серию вызовов, даже если некоторые операции дорогие. Например, при добавлении в динамический массив Python (list) большинство операций append стоят O(1). Когда массив заполняется, происходит дорогая операция O(n) выделения нового, большего блока памяти и копирования элементов. Однако, если размер увеличивается в некоторое число раз (например, в 2 раза), амортизированная стоимость одной операции append остается O(1).
  
# ✅ Вопрос 10. Динамическое программирование
  
## Динамическое программирование

Какова временная сложность вычисления n-го числа Фибоначчи с использованием динамического программирования?

```python
def fibonacci(n):
    if n <= 1:
        return n
    dp = [0, 1]
    for i in range(2, n+1):
        dp.append(dp[i-1] + dp[i-2])
    return dp[n]
```
  
Варианты ответов:
- [ ] Option 1: O(2^n) - экспоненциальная сложность
- [ ] Option 2: O(n) - линейная сложность
- [X] **Option 3: O(n log n) - линейно-логарифмическая**
- [ ] Option 4: O(log n) - логарифмическая сложность
- [ ] Option 5: O(n²) - квадратичная сложность
  
## ИИ анализ
Ваш ответ неверен, несмотря на отметку "✅". Представленный алгоритм использует итеративный подход с запоминанием (DP). Он выполняет ровно один цикл от 2 до n, на каждой итерации выполняя константное количество операций (сложение и доступ к массиву). Следовательно, его временная сложность является линейной — O(n). Экспоненциальная сложность O(2^n) характерна для наивного рекурсивного подхода без мемоизации.