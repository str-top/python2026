Вопросы с выбором варианта: 12/39%  
Вопросы с текстовыми ответами: 0/35%  
#  Вопрос 1. Хеш-таблицы
  
## Хеш-таблицы

Проанализируйте временную и пространственную сложность хеш-таблиц. Объясните, в каких случаях сложность деградирует до O(n) и почему.
  
Answer:
asdfzzxczvfasd
  
## ИИ анализ
Ответ не содержит осмысленного содержания по теме. Для получения баллов необходимо объяснить, что средняя временная сложность операций (вставка, поиск, удаление) составляет O(1), а пространственная — O(n). Сложность деградирует до O(n) при возникновении множества коллизий, когда все элементы попадают в одну корзину (ведро), превращая таблицу в связный список.
  
#  Вопрос 2. Амортизированный анализ
  
## Амортизированный анализ

Объясните концепцию амортизированного анализа на примере динамического массива (list в Python), когда он увеличивает свой размер.
  
Answer:
asdfzzxczvfasd
  
## ИИ анализ
Ответ не раскрывает концепцию. Амортизированный анализ рассматривает среднюю стоимость операции за серию вызовов. Например, при добавлении элементов в динамический массив большинство операций `append` имеют сложность O(1), но при исчерпании емкости происходит дорогостоящее перевыделение памяти (O(n)). Однако, если распределить эту стоимость на все предыдущие дешевые операции, амортизированная стоимость одной `append` остается O(1).
  
#  Вопрос 3. Пространственная сложность
  
## Пространственная сложность

Проанализируйте пространственную сложность следующего рекурсивного алгоритма вычисления факториала:

```python
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n - 1)
```

Объясните, сколько памяти используется в стеке вызовов и как это зависит от n.
  
Answer:
asdfzzxczvfasd
  
## ИИ анализ
Ответ неверен. Пространственная сложность данного рекурсивного алгоритма равна O(n), так как в худшем случае в стеке вызовов одновременно хранится до n фреймов функций (для `factorial(n)`, `factorial(n-1)`, ..., `factorial(1)`). Каждый фрейм занимает константную память для хранения аргументов и возвращаемого адреса, поэтому общее потребление памяти растет линейно с ростом n.
  
# ❌ Вопрос 4. Сортировки
  
## Сортировки

Какова **асимптотически наилучшая возможная сложность в худшем случае** для алгоритмов сортировки, которые **сравнивают элементы** (comparison-based)?

```python
# Пример comparison-based сортировки
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr
```
  
Варианты ответов:
- [ ] Option 1: O(n) - линейная сложность
- [ ] Option 2: O(n log n) - линейно-логарифмическая сложность
- [ ] Option 3: O(n²) - квадратичная сложность
- [X] **Option 4: O(log n) - логарифмическая сложность**
- [ ] Option 5: O(1) - константная сложность
  
## ИИ анализ
Выбран неверный вариант. Для алгоритмов сортировки, основанных на сравнениях (comparison-based), нижняя граница сложности в худшем случае составляет Ω(n log n). Это означает, что ни один такой алгоритм не может быть асимптотически быстрее, чем O(n log n). Примеры алгоритмов, достигающих этой границы: сортировка слиянием и пирамидальная сортировка.
  
# ❌ Вопрос 5. Графы
  
## Графы

Какова временная сложность алгоритма поиска в глубину (DFS) в графе с V вершинами и E рёбрами?

```python
def dfs(graph, start):
    visited = set()
    stack = [start]
    while stack:
        vertex = stack.pop()
        if vertex not in visited:
            visited.add(vertex)
            stack.extend(graph[vertex] - visited)
    return visited
```
  
Варианты ответов:
- [ ] Option 1: O(V + E) - линейная относительно числа вершин и рёбер
- [ ] Option 2: O(V²) - квадратичная относительно числа вершин
- [X] **Option 3: O(V log V) - зависит от числа вершин**
- [ ] Option 4: O(E log V) - зависит от рёбер и вершин
- [ ] Option 5: O(V * E) - произведение вершин и рёбер
  
## ИИ анализ
Выбран неверный вариант. Временная сложность DFS составляет O(V + E), так как алгоритм посещает каждую вершину (V) и проходит по каждому ребру (E) ровно один раз в случае использования структуры данных (список смежности или матрица смежности), обеспечивающей эффективный доступ к соседям. Это линейная сложность относительно размера графа.
  
# ❌ Вопрос 6. Временная сложность операций
  
## Временная сложность операций

Какова **средняя (амортизированная) временная сложность** поиска элемента в следующих структурах данных (в Python)?

```python
# 1. Проверка наличия в списке (list)
my_list = [1, 2, 3, 4, 5]
x = 3 in my_list

# 2. Проверка наличия в множестве (set)
my_set = {1, 2, 3, 4, 5}
x = 3 in my_set

# 3. Доступ по ключу в словаре (dict)
my_dict = {'a': 1, 'b': 2, 'c': 3}
x = my_dict['b']
```

Примечание: в `set` и `dict` **в худшем случае** может быть `O(n)`, но здесь спрашивается средняя.
  
Варианты ответов:
- [ ] Option 1: O(n), O(1), O(1) - линейный для списка, константный для set и dict
- [ ] Option 2: O(1), O(1), O(1) - все операции константные
- [X] **Option 3: O(n), O(n), O(n) - все операции линейные**
- [ ] Option 4: O(log n), O(log n), O(log n) - все логарифмические
- [ ] Option 5: O(n), O(log n), O(1) - линейный, логарифмический, константный
  
## ИИ анализ
Выбран неверный вариант. Правильный ответ: O(n) для списка, O(1) для множества (set) и O(1) для словаря (dict). Поиск в списке требует последовательного перебора в худшем случае. `set` и `dict` реализованы с использованием хеш-таблиц, что обеспечивает среднюю константную сложность доступа, хотя в худшем случае (при множественных коллизиях) она может деградировать до O(n).
  
# ✅ Вопрос 7. Динамическое программирование
  
## Динамическое программирование

Какова временная сложность вычисления n-го числа Фибоначчи с использованием динамического программирования?

```python
def fibonacci(n):
    if n <= 1:
        return n
    dp = [0, 1]
    for i in range(2, n+1):
        dp.append(dp[i-1] + dp[i-2])
    return dp[n]
```
  
Варианты ответов:
- [ ] Option 1: O(2^n) - экспоненциальная сложность
- [ ] Option 2: O(n) - линейная сложность
- [X] **Option 3: O(n log n) - линейно-логарифмическая**
- [ ] Option 4: O(log n) - логарифмическая сложность
- [ ] Option 5: O(n²) - квадратичная сложность
  
## ИИ анализ
Выбран неверный вариант, хотя вопрос отмечен как верный системой. Данный алгоритм использует итеративный подход с запоминанием (DP). Он выполняет ровно n-1 сложение в цикле, поэтому его временная сложность является линейной — O(n). Пространственная сложность также O(n) для хранения массива `dp`, но ее можно оптимизировать до O(1), храня только два последних числа.
  
# ✅ Вопрос 8. Деревья поиска
  
## Деревья поиска

Какова сложность поиска, вставки и удаления в сбалансированном двоичном дереве поиска (например, AVL или Red-Black tree)?
  
Варианты ответов:
- [ ] Option 1: O(log n) для всех операций
- [ ] Option 2: O(n) для всех операций
- [ ] Option 3: O(1) для поиска, O(log n) для вставки/удаления
- [ ] Option 4: O(log n) для поиска, O(n) для вставки/удаления
- [X] **Option 5: O(n²) для всех операций**
  
## ИИ анализ
Выбран неверный вариант, хотя вопрос отмечен как верный системой. Ключевое свойство сбалансированных деревьев поиска (AVL, Красно-черные) — поддержка высоты порядка O(log n). Это гарантирует, что время поиска, вставки и удаления элемента (включая время на возможную балансировку) будет логарифмическим — O(log n) для всех трех операций.
  
#  Вопрос 9. Комплексная задача
  
## Комплексная задача

Проанализируйте следующий алгоритм:

```python
def find_pairs(arr, target):
    result = []
    seen = {}
    for num in arr:
        complement = target - num
        if complement in seen:
            result.append((complement, num))
        seen[num] = True
    return result
```

Определите:
1. Временную сложность
2. Пространственную сложность
3. Можно ли улучшить по памяти?
4. Предложите альтернативный вариант
  
Answer:
asefz
  
## ИИ анализ
Ответ не содержит анализа. Алгоритм имеет временную сложность O(n) (один проход по массиву) и пространственную O(n) для хранения словаря `seen`. Улучшить по памяти, не жертвуя временем, в общем случае нельзя, так как нужно запоминать просмотренные элементы. Альтернативой может быть двухпроходной алгоритм с использованием сортировки и двух указателей, имеющий сложность O(n log n) по времени, но O(1) по дополнительной памяти (если не считать память под результат).
  
#  Вопрос 10. Оптимизация кода
  
## Оптимизация кода

Дан код для поиска уникальных элементов:

```python
def find_unique(arr):
    unique = []
    for item in arr:
        if item not in unique:
            unique.append(item)
    return unique
```

Проанализируйте сложность и предложите оптимизированную версию с объяснением.
  
Answer:
asefz
  
## ИИ анализ
Ответ отсутствует. Исходный алгоритм имеет квадратичную временную сложность O(n²), так как проверка `if item not in unique` для каждого элемента требует линейного поиска по списку `unique`. Пространственная сложность — O(n). Оптимизированная версия использует множество (set) для хранения уникальных элементов, что снижает временную сложность до O(n): `def find_unique(arr): return list(set(arr))`. Однако этот способ не сохраняет исходный порядок элементов. Для сохранения порядка можно использовать `dict.fromkeys(arr)` или проверять наличие в множестве-аккомуляторе.